---
layout: post
title: "Matando moscas a 'KaÃ±onazos'"
date: 2020-04-12 06:39:50
comments: true
description: "Matando moscas a caÃ±onazos, usando herramientas avanzadas del Mundo Devops, como Docker,TravisCI y Kubernetes."
keywords: "devops, developer, software"
comments: false
image: /images/rudder.jpg
summary: QuizÃ¡ al leer este articulo, no noten gran diferencia en la web, sigue siendo tan simple, y corta de contenidos como siempre, (no nos engaÃ±emos). Pero creedme que esto ha cambiado, y mucho. Si querÃ©is conocer las cosas que han cambiado, os invito a leer el post completo. 

---

![](/images/rudder-mini.jpg)

Una de las primeras cosas que me enseÃ±aron en el mundo de la informÃ¡tica es que debemos evitar "matar moscas a caÃ±onazos". 
Otra frase que me viene a la cabeza al escribir este post es "los experimentos con gaseosa".

Como habÃ©is podido comprobar no me caracterizo por escribir continuamente y la diferencia entre las fechas de publicaciones es muy amplia.

AsÃ­ que despuÃ©s de tanto tiempo sin escribir nada, este fin de semana, me sentÃ© en el ordenador decidido a escribir algo (sin saber muy bien que contar) aprovechando que hay que quedarse en casa dada la situaciÃ³n de alerta que estamos sufriendo por la COVID-19. 

Al descargarme el [repositorio](https://github.com/josemlp91/josemlp91.github.io_source) con el cÃ³digo fuente del blog, mi fuerza de voluntad empezÃ³ a flojear al recordad que uso **"Jekyll"** y eso significa que voy a tener que instalar un montÃ³n de cosas relacionadas con el ecosistema de **Ruby**. 

Siendo un lenguaje de programaciÃ³n que no suelo utilizar, me da gran pereza emborronar mi reciÃ©n formateado ordenador con multitud de dependencias y paquetes, que poco voy a aprovechar. 

DespuÃ©s de sopesarlo un momento, pienso que lo mejor es **Dockerizar** el proyecto y no volver a instalar dependencias de Jekyll. 

## Docker ğŸ‹

Lo primero que me interesa es poder desarrollar en local, aislando las dependencias y que sea *auto-instalable*.
Antes de nada paso a reestructurar los directorios y de paso limpiar ficheros que no se usan. 
Importante aÃ±adir al *.gitignore* el directorio "site" con los compilados. 

{% highlight sh %}
FROM jekyll/builder

RUN apk update && apk add --update nodejs nodejs-npm
WORKDIR /app/jekyll

COPY entrypoint.sh /entrypoint
RUN sed -i 's/\r//' /entrypoint
RUN chmod +x /entrypoint

ENTRYPOINT ["/entrypoint"]
{% endhighlight %}

Al ser una versiÃ³n para desarrollo, me ha parecido mÃ¡s cÃ³modo hacer la instalaciÃ³n de dependencias
en tiempo de ejecuciÃ³n ``entrypoint``.

{% highlight sh %}
#!/bin/sh

set -o errexit
set -o nounset

bundle install
exec "$@"
{% endhighlight %}

Mi memoria es bastante limitada, por ello escribo un **docker-compose** para desarrollo, 
asÃ­ ya no tengo que estar recordando las diferentes opciones, volÃºmenes y puertos que debo aÃ±adir al arrancar el contenedor.
La orden a invocar es ``jekyll serve`` (para el servidor de pruebas) y el puerto 4000.

{% highlight yaml %}
version: '3'

services:
  web:
    build:
      context: .
      dockerfile: Dockerfile.dev
    ports:
      - "8080:80"
    volumes:
      - "./jekyll:/app/jekyll/"
    ports:
      - 4000:4000
    command: jekyll serve
{% endhighlight %}

Con ello ya estarÃ­a, puedo escribir mi post sin tener que preocuparme por instalar dependencias. 
Pero ya puestos no me puedo quedar aquÃ­ y pienso en crear una imÃ¡gen que en un futuro pueda usar para desplegar la aplicaciÃ³n en producciÃ³n 
y almacenarla en algÃºn registro como **Docker Hub**.

DespuÃ©s de pensar un poco, creo que la opciÃ³n mÃ¡s limpia es usar **"multi-stage"**.
Y como podemos ver a continuaciÃ³n, el primer stage, se ocupa de hacer la compilaciÃ³n 
y el segundo stage, es un servidor nginx alpine con ello consigo que la imÃ¡gen Docker pese menos de **14 MB**.

{% highlight sh %}
FROM jekyll/builder as builder

RUN apk update && apk add --update nodejs nodejs-npm
WORKDIR /app/jekyll
COPY ./jekyll/Gemfile* /app/jekyll/
RUN bundle install
COPY ./jekyll /app/jekyll/
RUN mkdir -p /app/jekyll/_site && jekyll build

FROM nginx:alpine

RUN rm -f /etc/nginx/conf.d/* && rm -rf /app/*
COPY --from=builder /app/jekyll/_site /app
COPY ./nginx/default.conf /etc/nginx/conf.d/
{% endhighlight %}


Pero ya no me puedo quedar quieto, Â¿y si trato de desplegar? ğŸ‘·

## Kubernetes âš“ï¸

Hace un tiempo, estuve haciendo un curso de Kubernetes y aÃºn mantengo la instalaciÃ³n de **"Minikube"**. 
Por tanto, es una buena oportunidad de probar.

Empezamos creando un **Deployment** y un **Service** bÃ¡sico en el fichero ``josemlp91-myblog.yml``.

{% highlight yaml %}

apiVersion: v1
kind: Service
metadata:
  name: josemlp91-myblog
spec:
  type: ClusterIP
  ports:
  - port: 80
    targetPort: 80
  selector:
    app: josemlp91-myblog
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: josemlp91-myblog
spec:
  replicas: 1
  selector:
    matchLabels:
      app: josemlp91-myblog
  template:
    metadata:
      labels:
        app: josemlp91-myblog
    spec:
      containers:
      - name: josemlp91-myblog
        image: josemlp91/myblog:latest
        ports:
        - containerPort: 80

{% endhighlight %}

{% highlight sh %}
kubectl create -f josemlp91-myblog.yml
{% endhighlight %}

Y veo que funciona. Subidon de adrenalina. ğŸˆ ğŸŠ ğŸ‰

En este punto ya no me puedo quedar aquÃ­, despuÃ©s de darle algunas vueltas,
decido empezar a buscar un clÃºster **K8S** en la nube donde hacer mi experimento. 

Lo primero que se me ocurre es tirar de Amazon, Google Cloud o Azure â˜ï¸ 
(ademÃ¡s alguno de ellos ofrece crÃ©dito de forma gratuita para hacer pruebas). 
Pero creo que hay que darle un puntito de emociÃ³n a la cosa y tratar de instalar un clÃºster kubernetes.
Puede ser un buen reto ğŸ’ª (estoy confinado en casa y tengo todo el puente...).

Comienzo a comparar diferentes proveedores de **Servidores Cloud VPS** 
y consigo encontrar uno que me convence en relaciÃ³n calidad-precio. 
Teniendo en cuenta que necesito tener dos como mÃ­nimo (nodo mÃ¡ster y un worker) y que el master debe tener **2GB de RAM y 2 cores**. 

Con mis flamantes mÃ¡quinas, comienzo a instalar todo. No me extiendo en explicar el proceso, dado que es largo.
Dejo las fuentes que he seguido al final del post. â¬‡ï¸
Y este seria el resultado.

![](/images/nodes.png)

Y ya puedo repetir lo mismo que hacÃ­a en minikube pero esta vez con un clÃºster de producciÃ³n.

Para que sea completamente operativo, es esencial crear un ingress, en mi caso me decanto por la implementaciÃ³n
con Nginx aunque existen muchas otras opciones, entre ellas Traefik y HAProxy. 

En este punto tambiÃ©n conozco la herramienta **Helm** con la cual implementar el ingress es un poco mÃ¡s simple.

{% highlight sh %}
helm install stable/nginx-ingress --name my-nginx  \ 
--set controller.publishService.enabled=true
{% endhighlight %}

{% highlight yaml %}
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  annotations:
    kubernetes.io/ingress.class: nginx
  name: hello-kubernetes-ingress
spec:
  tls:
  - hosts:
    - josemiguelopez.es
    secretName: echo-tls
  rules:
    - host: hellok8s.josemiguelopez.es
      http:
        paths:
          - backend:
              serviceName: hello-kubernetes-first
              servicePort: 80
            path: /
    - host: josemiguelopez.es
      http:
        paths:
        - backend:
            serviceName: josemlp91-myblog
            servicePort: 80
          path: /
{% endhighlight %}

{% highlight sh %}
kubectl create -f first-ingress.yaml
{% endhighlight %}

Con esto solo me queda modificar la entrada de mi **dominio** para hacerla apuntar a la Ip pÃºblica del nodo mÃ¡ster de mi cluster.

![](/images/pods.png)

## Desplegando ğŸš€

Probamos que tras actualizar la imagen podemos actualizar el **Deployment** con la nueva versiÃ³n.
Para que todo sea automÃ¡tico creo un **Makefile** con la operaciÃ³n "publish" que se ocupa de:

- Construir imÃ¡genes
- Subirlas a Docker Hub
- Actualizar el Deployment de K8S. 

{% highlight makefile %}

DOCKER_USERNAME = josemlp91
DOCKER_IMAGE_NAME = myblog
K8S_DEPLOYMENT_NAME = josemlp91-myblog

gitver=$(shell git log -1 --pretty=format:"%H")

publish:  ## Publish image in Docker Hub.
	docker login
	docker build -f Dockerfile.prod -t \ 
	 $(DOCKER_USERNAME)/$(DOCKER_IMAGE_NAME):$(gitver) .
	docker push $(DOCKER_USERNAME)/$(DOCKER_IMAGE_NAME):$(gitver)
	docker tag $(DOCKER_USERNAME)/$(DOCKER_IMAGE_NAME):$(gitver) \
	 $(DOCKER_USERNAME)/$(DOCKER_IMAGE_NAME):latest
	docker push $(DOCKER_USERNAME)/$(DOCKER_IMAGE_NAME):latest
	kubectl set image deployment/$(K8S_DEPLOYMENT_NAME) \ 
	 $(K8S_DEPLOYMENT_NAME)= \
	 $(DOCKER_USERNAME)/$(DOCKER_IMAGE_NAME):$(gitver)

{% endhighlight %}

## IntegraciÃ³n continua âš™ï¸ â›“

En este punto, lo interesante serÃ­a que todo esto se haga de forma automÃ¡tica al hacer un commit en github (rama master).
Para ello, recurro a TravisCI que ya esta integrado directamente con GitHub y es gratuito con proyectos de cÃ³digo abierto.

AsÃ­ queda el archivo ``.travis.yml`` dÃ³nde lo importante es definir la configuraciÃ³n para conectarte a K8S mediante variables de entorno secretas.

Otro punto a tener en cuenta, ha sido la instalaciÃ³n de "kubectl" en la mÃ¡quina de Travis. DespuÃ©s de probar varias alternativas,
he podido comprobar que lo mÃ¡s rÃ¡pido es usar una imagen de docker auxiliar que ya tiene la utilidad "kubectl" instalada. 

{% highlight yaml %}

services:
  - docker

branches:
  only:
  - master

env:
  global:
    - DOCKER_IMAGE_NAME="myblog"
    - K8S_DEPLOYMENT_NAME="josemlp91-myblog"

before_install:
  - docker pull smesch/kubectl
  - docker login -u "${DOCKER_USERNAME}" -p "${DOCKER_PASSWORD}"

script:
  - touch kubeconfig
  - docker login -u "${DOCKER_USERNAME}" -p "${DOCKER_PASSWORD}" docker.io
  - docker build -f Dockerfile.prod -t  \ 
    ${DOCKER_USERNAME}/${DOCKER_IMAGE_NAME}:${TRAVIS_COMMIT} .
  - docker push ${DOCKER_USERNAME}/${DOCKER_IMAGE_NAME}:${TRAVIS_COMMIT}
  - docker tag ${DOCKER_USERNAME}/${DOCKER_IMAGE_NAME}:${TRAVIS_COMMIT} \
    ${DOCKER_USERNAME}/${DOCKER_IMAGE_NAME}:latest
  - docker push ${DOCKER_USERNAME}/${DOCKER_IMAGE_NAME}:latest
  - sed -i -e 's|KUBE_CA_CERT|'"${KUBE_CA_CERT}"'|g' kubeconfig
  - sed -i -e 's|KUBE_ENDPOINT|'"${KUBE_ENDPOINT}"'|g' kubeconfig
  - sed -i -e 's|KUBE_ADMIN_CERT|'"${KUBE_ADMIN_CERT}"'|g' kubeconfig
  - sed -i -e 's|KUBE_ADMIN_KEY|'"${KUBE_ADMIN_KEY}"'|g' kubeconfig
  - echo "Ready to deploy in K8S."
  - docker run -v ${TRAVIS_BUILD_DIR}:/kube smesch/kubectl kubectl \
    --kubeconfig /kube/kubeconfig set image \
    deployment/${K8S_DEPLOYMENT_NAME} \ 
    ${K8S_DEPLOYMENT_NAME}= \
    ${DOCKER_USERNAME}/${DOCKER_IMAGE_NAME}:$TRAVIS_COMMIT

{% endhighlight %}

## Conclusiones ğŸ”®

Cuando decÃ­a antes que "mataba moscas a caÃ±onazos" querÃ­a referirme a que no es necesario hacer tal despliegue de tecnologÃ­as y componentes para poner en producciÃ³n una **web estÃ¡tica**. AdemÃ¡s creo que en ciertas situaciones puede ser peligroso puesto que a la par que automatizo el proceso incremento la complejidad del sistema y la respuesta ante un posible error sea menos Ã¡gil, obligÃ¡ndonos a mirar y rebuscar logs en varios elementos. 
Siempre hay que pensar en la mejor herramienta a nuestro problema.

Las tecnologÃ­as **Devops** y en particular **Docker y Kubernetes** me parece un mundo asombroso y es por ello que me he tomado este tiempo en hacer este ejercicio y poder contarlo.

Espero poder seguir montando servicios mÃ¡s interesantes e ir escribiendo un poco mÃ¡s a menudo. 


## Referencias ğŸ“–

- [Jekyll is a simple, blog-aware, static site generato](https://jekyllrb.com/)
- [The package manager for Kubernetes](https://helm.sh/)
- [CÃ³mo crear un clÃºster de Kubernetes usando Kubeadm en Ubuntu 18.04](https://www.digitalocean.com/community/tutorials/how-to-create-a-kubernetes-cluster-using-kubeadm-on-ubuntu-18-04-es)
- [CÃ³mo configurar un Ingress de Nginx con Cert-Manager en Kubernetes de DigitalOcean](https://www.digitalocean.com/community/tutorials/how-to-set-up-an-nginx-ingress-with-cert-manager-on-digitalocean-kubernetes-es)
- [How To Set Up an Nginx Ingress on DigitalOcean Kubernetes Using Helm](https://www.digitalocean.com/community/tutorials/how-to-set-up-an-nginx-ingress-on-digitalocean-kubernetes-using-helm)
- [Continuous Deployment with Travis CI and Kubernetes](https://kumorilabs.com/blog/k8s-8-continuous-deployment-travis-ci-kubernetes/)

## WARNING âš ï¸

> El cÃ³digo fuente incrustado aquÃ­ puede presentar problemas de formateado (dado que he tratado de adaptarlo a pantallas de mÃ³vil).
Puedes consultar la versiÃ³n original en el repositorio de cÃ³digo fuente.

> Es un ejemplo didÃ¡ctico, Ãºsalo bajo tu responsabilidad.
